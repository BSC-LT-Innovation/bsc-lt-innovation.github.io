<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Bokeh Plot</title>
    <style>
      html, body {
        box-sizing: border-box;
        display: flow-root;
        height: 100%;
        margin: 0;
        padding: 0;
      }
    </style>
    <script type="text/javascript" src="https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js"></script>
    <script type="text/javascript">
        Bokeh.set_log_level("info");
    </script>
  </head>
  <body>
    <div id="eea16c0c-f0cf-4b3d-95ee-12732e5d07be" data-root-id="p3592" style="display: contents;"></div>
  
    <script type="application/json" id="d6204fc8-5f6e-403e-8246-0b496ddc0b68">
      {"2344d1c4-eef1-404c-ae45-9b0010feaf3e":{"version":"3.6.2","title":"Bokeh Application","roots":[{"type":"object","name":"Figure","id":"p3592","attributes":{"sizing_mode":"stretch_both","x_range":{"type":"object","name":"DataRange1d","id":"p3593"},"y_range":{"type":"object","name":"DataRange1d","id":"p3594"},"x_scale":{"type":"object","name":"LinearScale","id":"p3602"},"y_scale":{"type":"object","name":"LinearScale","id":"p3603"},"title":{"type":"object","name":"Title","id":"p3595","attributes":{"text":"\nModel: BAAI/bge-m3\nDataset: Aina Challenge\nDataset size: 36\nEmbeddings shape: (36, 1024)\nDim. reduction: UMAP (params: {'n_neighbors': 4, 'min_dist': 0.1, 'metric': 'cosine', 'random_state': 42})\nTopics: Aina Kit (blue): 24, Modelo Salamandra\u20117B-instruct (orange): 12\n","text_font_size":"0.85em","text_font_style":"normal"}},"renderers":[{"type":"object","name":"GlyphRenderer","id":"p3637","attributes":{"data_source":{"type":"object","name":"ColumnDataSource","id":"p3628","attributes":{"selected":{"type":"object","name":"Selection","id":"p3629","attributes":{"indices":[],"line_indices":[]}},"selection_policy":{"type":"object","name":"UnionRenderers","id":"p3630"},"data":{"type":"map","entries":[["x",{"type":"ndarray","array":{"type":"bytes","data":"zkESQelJDkGzLgNBCvUQQRhjEkHKpAhBRZoFQVZQCEEuJLJAIHumQMtzq0DePBlBbQEVQYAMo0CX3KNA/AIcQbMQH0HwB/NAfkoOQQYSEEH4WQ1B3xUXQWVXp0C+nLFAEi7qQIlx3ED71OZAE070QPuf9EDrZAVBCAjcQKir6EBmRvhAwCXxQGXoAkHKF/9A"},"shape":[36],"dtype":"float32","order":"little"}],["y",{"type":"ndarray","array":{"type":"bytes","data":"f+zHQD/TukAFxgxBwtHEQLUlqED037BA5dWSQFeymEB+naZAPxybQER7lUBs9D3AAEEUwOQ6jkBELbRAYxVSwLDHW8CCpCZBRt2eQBWbhkAXWopAtDpPwGq4p0BYaLFA8WweQSOKIkFL9ylBMfUVQVddIUEAshZBt3AqQV/1M0F1MzBBBbU3QYQ7HkEO8gpB"},"shape":[36],"dtype":"float32","order":"little"}],["topic",{"type":"ndarray","array":["Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Aina Kit","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct","Modelo Salamandra\u20117B-instruct"],"shape":[36],"dtype":"object","order":"little"}],["question",{"type":"ndarray","array":["Aina Kit&lt;br&gt;Cobertura de idiomas de Aina Kit&lt;br&gt;La mayor\u00eda de los modelos del Aina Kit son multiling\u00fces con un soporte especialmente s\u00f3lido para el catal\u00e1n. Las familias Salamandra (2B/7B) y ALIA-40B fueron entrenadas en 35 lenguas europeas, entre ellas catal\u00e1n, espa\u00f1ol, ingl\u00e9s y franc\u00e9s; esta cobertura permite comprender y generar texto en m\u00faltiples idiomas dentro del mismo modelo. Adem\u00e1s, existen modelos especializados centrados exclusivamente en catal\u00e1n o en escenarios bi/tri-ling\u00fces (catal\u00e1n, espa\u00f1ol, ingl\u00e9s) cuando la tarea lo requiere. En todos los casos, el catal\u00e1n tiene soporte pleno debido al enfoque del proyecto AINA en este idioma.","Aina Kit&lt;br&gt;Familias de modelos de texto en Aina Kit&lt;br&gt;Aina Kit ofrece varias familias de modelos con casos de uso diferenciados. Salamandra es la generaci\u00f3n m\u00e1s reciente y avanzada de LLMs: modelos multiling\u00fces entrenados desde cero en el superordenador MareNostrum 5, disponibles en tama\u00f1os 2B y 7B, y en variantes base, instruidas y adaptadas a tareas espec\u00edficas; son la opci\u00f3n recomendada para nuevos proyectos generativos. ALIA incluye ALIA-40B, el modelo m\u00e1s grande de la iniciativa (40 mil millones de par\u00e1metros), con la misma arquitectura/datos multiling\u00fces y especial \u00e9nfasis en las lenguas cooficiales de Espa\u00f1a. FLOR es una familia triling\u00fce (catal\u00e1n, espa\u00f1ol, ingl\u00e9s) basada en Bloom, reentrenada por el BSC, con tama\u00f1os como 6.3B y 1.3B y versiones instruidas; est\u00e1 oficialmente deprecada y sustituida por Salamandra/ALIA. La familia RoBERTa re\u00fane encoders optimizados para catal\u00e1n (no generativos) que destacan en clasificaci\u00f3n, NER, QA y creaci\u00f3n de embeddings densos.","Aina Kit&lt;br&gt;Tipos de modelo: fundacional, instruido y adaptado&lt;br&gt;Un modelo fundacional (p. ej., salamandra-7b o ALIA-40B) aprende a predecir el siguiente token sobre un corpus masivo, acumulando conocimiento ling\u00fc\u00edstico y factual, pero sin estar optimizado para seguir instrucciones de usuario. Un modelo instruido (p. ej., salamandra-7b-instruct) parte del fundacional y recibe una segunda fase de ajuste con miles de pares instrucci\u00f3n-respuesta (como InstruCAT), de modo que se comporta como asistente conversacional. Un modelo adaptado a tareas espec\u00edficas es un modelo ajustado para una funci\u00f3n concreta (NER, clasificaci\u00f3n, POS, etc.), ofreciendo mejor rendimiento en ese \u00e1mbito a cambio de menor versatilidad general.","Aina Kit&lt;br&gt;Modelos recomendados para NER en catal\u00e1n&lt;br&gt;Para reconocimiento de entidades en catal\u00e1n, Aina Kit recomienda: roberta-base-ca-v2-cased-ner (adaptado con AnCora-Ca-NER) y multiner_ceil (basado en RoBERTa-base-ca-v2 y adaptado con CEIL) cuando el flujo sea exclusivamente en catal\u00e1n y se busque el m\u00e1ximo rendimiento. Si se requiere un \u00fanico modelo para flujos multiling\u00fces (catal\u00e1n, espa\u00f1ol, ingl\u00e9s), la opci\u00f3n aconsejada es DEBERTA_CIEL, basado en deberta-v3-large y entrenado con el conjunto de datos CEIL.","Aina Kit&lt;br&gt;Embeddings de palabras disponibles&lt;br&gt;Aina Kit ofrece embeddings CBOW en catal\u00e1n entrenados con aproximadamente 34 GB de texto y distribuidos en formato Floret, una variante eficiente de FastText que reduce la huella de memoria y acelera su uso en aplicaciones de PLN. Estos embeddings son adecuados como representaciones sem\u00e1nticas para tareas de recuperaci\u00f3n, clasificaci\u00f3n y clustering.","Aina Kit&lt;br&gt;Qu\u00e9 es RAG y qu\u00e9 ofrece Aina Kit&lt;br&gt;RAG (Retrieval-Augmented Generation) conecta un LLM a una base de conocimiento externa para incorporar informaci\u00f3n actualizada y reducir alucinaciones. El sistema primero recupera pasajes relevantes (p. ej., desde documentaci\u00f3n interna o PDFs) y se los aporta al modelo como contexto antes de generar una respuesta. Aina Kit dispone de modelos instruidos compatibles con flujos RAG (Salamandra-7B-instruct, Salamandra-2B-instruct) y del dataset RAG_Multilingual, con m\u00e1s de 56 mil ejemplos de preguntas, contextos y respuestas en catal\u00e1n, espa\u00f1ol e ingl\u00e9s, dise\u00f1ado para entrenar y evaluar sistemas RAG.","Aina Kit&lt;br&gt;Modelos de voz: TTS y ASR&lt;br&gt;El Aina Kit incluye modelos de voz para dos tareas fundamentales: s\u00edntesis de voz (TTS), que convierte texto a audio, y reconocimiento autom\u00e1tico del habla (ASR), que transcribe audio a texto. Cada modelo cuenta con su descripci\u00f3n y disponibilidad en la p\u00e1gina de modelos de voz del proyecto.","Aina Kit&lt;br&gt;Modelos de texto vs. modelos de traducci\u00f3n autom\u00e1tica&lt;br&gt;Los modelos de texto de Aina Kit son de prop\u00f3sito general y cubren generaci\u00f3n, comprensi\u00f3n y manipulaci\u00f3n de lenguaje en diversos contextos. Los modelos de traducci\u00f3n autom\u00e1tica est\u00e1n espec\u00edficamente orientados a convertir texto de un idioma a otro con alta fidelidad. La elecci\u00f3n depende del objetivo: versatilidad para redactar, resumir o dialogar (modelos de texto) frente a precisi\u00f3n en pares ling\u00fc\u00edsticos (modelos de traducci\u00f3n).","Aina Kit&lt;br&gt;Disponibilidad: API y despliegue&lt;br&gt;Actualmente Aina Kit no ofrece una API propia: publica los modelos en Hugging Face con sus model cards, lo que permite descargarlos y desplegarlos con frameworks como Transformers, FastAPI o Gradio, o usarlos mediante endpoints de inferencia en plataformas como Hugging Face Inference Endpoints, AWS o Azure. Esta v\u00eda facilita tanto pruebas locales como despliegues gestionados.","Aina Kit&lt;br&gt;C\u00f3mo empezar a usar los modelos localmente&lt;br&gt;Para comenzar, se puede probar en Spaces de Hugging Face (ChatUI) para inferencia r\u00e1pida; instalar localmente con Python descargando pesos desde Hugging Face y cargando con Transformers (creando un entorno virtual e instalando torch/transformers); o usar herramientas como Ollama y LM Studio si existen pesos en formato GGUF (la conversi\u00f3n es posible con llama.cpp). Las model cards incluyen fragmentos de c\u00f3digo y notebooks en Colab/Kaggle para acelerar los prototipos.","Aina Kit&lt;br&gt;Opciones de despliegue en producci\u00f3n&lt;br&gt;El despliegue en producci\u00f3n puede realizarse con Hugging Face Inference Endpoints (bot\u00f3n Deploy en la p\u00e1gina del modelo, con opciones como escalado autom\u00e1tico o cuantizaci\u00f3n), con Amazon SageMaker (HuggingFaceModel y variable HF_MODEL_ID para crear un endpoint gestionado de GPU que escale bajo demanda), con servicios de IA de nubes p\u00fablicas (AWS/GCP/Azure), o en infraestructura propia mediante frameworks como FastAPI/Flask o el contenedor Text-Generation-Inference (TGI) de Hugging Face para servir LLMs a escala.","Aina Kit&lt;br&gt;Fine-tuning y licencias de los modelos&lt;br&gt;El fine-tuning es posible siempre que la licencia lo permita. Los modelos publicados con Apache 2.0 permiten modificaciones y uso comercial manteniendo avisos y la licencia original. Modelos con CC-BY requieren atribuci\u00f3n; CC-BY-SA obliga a compartir modificaciones bajo la misma licencia; CC-BY-NC proh\u00edbe uso comercial; sin licencia expl\u00edcita no se concede permiso. Antes de ajustar, es imprescindible revisar la model card y su licencia.","Aina Kit&lt;br&gt;Cu\u00e1ndo conviene hacer fine-tuning&lt;br&gt;El fine-tuning debe considerarse solo cuando t\u00e9cnicas como ingenier\u00eda de instrucciones (prompt engineering, few-shot, chain-of-thought) o RAG no resuelvan el caso de uso. Estas alternativas suelen ser m\u00e1s r\u00e1pidas, baratas y flexibles, adem\u00e1s de permitir citar fuentes y mantener la base de conocimiento actualizada sin reentrenar el modelo.","Aina Kit&lt;br&gt;C\u00f3mo hacer fine-tuning en la pr\u00e1ctica&lt;br&gt;En modalidad low/no-code, puede usarse Hugging Face AutoTrain desde la p\u00e1gina del modelo o Amazon SageMaker con plantillas disponibles. De forma program\u00e1tica, Transformers ofrece la clase Trainer y scripts cl\u00e1sicos (run_clm.py, run_mlm.py). Para eficiencia, PEFT congela el modelo base y entrena peque\u00f1as capas adaptadoras (LoRA), y QLoRA combina LoRA con cuantizaci\u00f3n para reducir a\u00fan m\u00e1s memoria, permitiendo ajustar modelos grandes en GPUs de consumo.","Aina Kit&lt;br&gt;Function calling y uso de herramientas&lt;br&gt;Las variantes instruidas del Aina Kit no incluyen de forma nativa una API de function calling o tool use en esta versi\u00f3n, aunque est\u00e1 en desarrollo por el BSC. Aun as\u00ed, se pueden construir flujos de agentes implementando manualmente las llamadas a herramientas en el orquestador de la aplicaci\u00f3n.","Aina Kit&lt;br&gt;Licencias de los modelos en Aina Kit&lt;br&gt;La mayor\u00eda de modelos se publican bajo Apache 2.0, una licencia permisiva que admite uso, modificaci\u00f3n y distribuci\u00f3n, incluso con fines comerciales. Algunos modelos concretos, como Matxa-TTS, tienen restricciones (solo uso no comercial). Siempre hay que verificar la licencia espec\u00edfica en la p\u00e1gina correspondiente.","Aina Kit&lt;br&gt;Implicaciones pr\u00e1cticas de Apache 2.0&lt;br&gt;Apache 2.0 concede derechos amplios de uso, modificaci\u00f3n y sublicencia, incluida una concesi\u00f3n expl\u00edcita de patentes por parte de los contribuidores. Obliga a conservar avisos de copyright y el texto de la licencia, e indicar los cambios si se modifica el software o el modelo. No es copyleft: no exige que las obras derivadas se distribuyan con la misma licencia ni publicar el c\u00f3digo fuente.","Aina Kit&lt;br&gt;Requisitos de hardware para ejecutar modelos&lt;br&gt;La VRAM necesaria depende del tama\u00f1o del modelo y la precisi\u00f3n: como regla aproximada, cada par\u00e1metro ocupa ~4 bytes en FP32, 2 bytes en FP16, ~1 byte en INT8 y ~0.5 byte en formatos de 4 bits. Por ejemplo, Salamandra-7B (~7.8B par\u00e1metros) requiere en torno a 14\u201316 GB en FP16, ~10 GB en INT8 y ~5 GB en 4-bit, pudiendo funcionar en tarjetas de 8 GB si las secuencias no son largas. Es buena pr\u00e1ctica sumar RAM del sistema y VRAM de la GPU, elegir un archivo de pesos algo menor que esa suma y controlar la KV-cache y la longitud de contexto para evitar errores de memoria.","Aina Kit&lt;br&gt;Tipos de datasets disponibles en Aina Kit&lt;br&gt;Para modelos de texto, hay corpora masivos y colecciones curadas para fine-tuning y evaluaci\u00f3n (clasificaci\u00f3n, an\u00e1lisis de sentimientos, detecci\u00f3n de emociones, QA, resumen, lenguaje abusivo, etc.), adem\u00e1s de conjuntos de instrucciones. Para voz, existen corpus ASR/TTS, multidialectales y con diferentes registros; para traducci\u00f3n autom\u00e1tica, grandes corpus paralelos catal\u00e1n-otras lenguas y colecciones de dominio para adaptar y evaluar pares como catal\u00e1n-ingl\u00e9s, catal\u00e1n-espa\u00f1ol o catal\u00e1n-franc\u00e9s.","Aina Kit&lt;br&gt;Herramientas para suministro de datos de texto&lt;br&gt;El ecosistema incluye un extractor de Wikipedia (Viquip\u00e8dia) para obtener grandes vol\u00famenes de documentos, una pipeline automatizada para procesar datos abiertos del DOGC, y un anonimizador que cumple con GDPR para proteger datos sensibles. Los enlaces est\u00e1n disponibles en la p\u00e1gina de datasets y herramientas de texto.","Aina Kit&lt;br&gt;Herramientas para suministro de datos de voz&lt;br&gt;Aina Kit provee Datapipe y Found Speech Pipeline, dise\u00f1adas para crear corpus de habla alineados con transcripciones o subt\u00edtulos a partir de fuentes como YouTube y parlamentos auton\u00f3micos. Estas herramientas automatizan el alineamiento audio-texto y facilitan la creaci\u00f3n de datasets de alta calidad para ASR y TTS.","Aina Kit&lt;br&gt;Licencias de los datasets&lt;br&gt;Los conjuntos de datos del Aina Kit se publican bajo diversas licencias Creative Commons (CC). Es imprescindible consultar la licencia aplicable al dataset concreto para entender si requiere atribuci\u00f3n, si impone compartir-igual (SA) o si restringe el uso comercial (NC).","Aina Kit&lt;br&gt;Demostradores y acceso r\u00e1pido&lt;br&gt;El proyecto mantiene varios demostradores en Hugging Face Spaces con API gratuita: un sistema de traducci\u00f3n multiling\u00fce, un chat (ChatUI) con distintos modelos, un TTS multihablantes, una aplicaci\u00f3n de transcripci\u00f3n fon\u00e9tica y un clasificador de modelos de texto a voz. El ChatUI puede tardar 5\u201310 minutos en iniciarse si el modelo correspondiente est\u00e1 apagado.","Aina Kit&lt;br&gt;Comunidad y c\u00f3mo mantenerse al d\u00eda&lt;br&gt;El proyecto Aina evoluciona de forma continua. Para seguir novedades, resolver dudas o contribuir, se ofrecen un canal de Discord, las p\u00e1ginas del BSC y del Proyecto Aina en Hugging Face y el repositorio en GitHub. Est\u00e1 previsto un sistema RAG entrenado con datos del Aina Kit que se publicar\u00e1 pr\u00f3ximamente.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Salamandra: descripci\u00f3n general y licencia&lt;br&gt;Salamandra es una familia de modelos multiling\u00fces preentrenados desde cero que incluye tama\u00f1os de 2B, 7B y 40B par\u00e1metros, con variantes base e instruidas. Esta secci\u00f3n se refiere a la versi\u00f3n instruida de 7B. Toda la familia se publica con una licencia Apache 2.0 permisiva y, adem\u00e1s de los pesos abiertos, se liberan scripts de entrenamiento y archivos de configuraci\u00f3n en un repositorio p\u00fablico.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Preentrenamiento y alcance de datos en Salamandra&lt;br&gt;El modelo es un decoder-only preentrenado desde cero sobre aproximadamente 12.875 billones de tokens de datos altamente curados. El corpus de preentrenamiento abarca 35 lenguas europeas y 92 lenguajes de programaci\u00f3n. En las primeras tres \u00e9pocas (2.4T tokens/\u00e9poca) se ajustaron proporciones para dar m\u00e1s peso a las lenguas cooficiales de Espa\u00f1a, reduciendo a la mitad ingl\u00e9s y c\u00f3digo; en \u00e9pocas posteriores, el componente en ingl\u00e9s de Colossal OSCAR se sustituy\u00f3 por FineWeb-Edu (subset 350BT), hasta alcanzar 2.68T tokens por \u00e9poca, m\u00e1s una \u00faltima \u00e9poca de 0.315T con datos de mayor calidad.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Arquitectura y especificaciones de Salamandra-7B-Instruct&lt;br&gt;El modelo cuenta con 7,768,117,248 par\u00e1metros totales, de los cuales 1,048,576,000 corresponden a embeddings. Integra 32 capas con tama\u00f1o oculto 4,096 y 32 cabezas de atenci\u00f3n, longitud de contexto 8,192 y vocabulario de 256,000. Opera en precisi\u00f3n bfloat16, usa embeddings rotatorios (RoPE), activaci\u00f3n SwiGLU y normalizaci\u00f3n RMSNorm; soporta Flash Attention y GQA con 8 grupos de consultas.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Usos previstos y limitaciones&lt;br&gt;Los modelos est\u00e1n destinados a investigaci\u00f3n y uso comercial en los idiomas presentes en los datos de entrenamiento. Las variantes base sirven para generaci\u00f3n y como punto de partida para ajustes espec\u00edficos; las versiones instruidas se utilizan como asistentes generales, con las limitaciones inherentes. Quedan fuera de alcance usos maliciosos o despliegues irresponsables sin evaluaci\u00f3n y mitigaci\u00f3n de riesgos.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Infraestructura y framework de entrenamiento&lt;br&gt;El preentrenamiento se realiz\u00f3 con NVIDIA NeMo sobre PyTorch Lightning para entrenamiento distribuido eficiente, mientras que las versiones instruidas se ajustaron con FastChat. Todo el entrenamiento tuvo lugar en MareNostrum 5 (BSC), un superordenador pre-exascala con 1,120 nodos acelerados: cada nodo incorpora 4 GPU NVIDIA Hopper de 64 GB HBM, 2 CPU Intel Sapphire Rapids 8460Y+ (64 n\u00facleos en total por nodo), interconexi\u00f3n 4\u00d7 NDR200, 512 GB de RAM y 460 GB de NVMe. A nivel de c\u00f3mputo, el entrenamiento emple\u00f3 aproximadamente 256 GPU para 2B, 512 para 7B y entre 1,024 y 2,048 para 40B.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Plantilla conversacional (ChatML) para inferencia&lt;br&gt;Las variantes instruidas usan una plantilla de chat tipo ChatML: cada turno va precedido por &lt;|im_start|&gt; y el rol ('system', 'user' o 'assistant') y finaliza con &lt;|im_end|&gt;. La forma m\u00e1s sencilla de aplicarla es con tokenizer.apply_chat_template del tokenizer de Transformers, incluyendo un date_string para contextualizar la fecha. Respetar la alternancia de roles (usuario/asistente) mejora la estabilidad y la calidad de generaci\u00f3n.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Datos de ajuste de instrucciones&lt;br&gt;La variante instruida se afin\u00f3 con una colecci\u00f3n de aproximadamente 273 mil instrucciones, enfocada en catal\u00e1n, ingl\u00e9s y espa\u00f1ol; tambi\u00e9n se incluyeron ejemplos en lenguas ib\u00e9ricas relacionadas que mostraron un impacto positivo en los idiomas de inter\u00e9s. Entre los conjuntos empleados se encuentran alpaca-cleaned, aya-dataset, coqcat, databricks-dolly-15k, dolly-ca, flores-dev, mentor-ca, mentor-es, no-robots, oasst-ca, oasst2, open-orca, rag-multilingual y tower-blocks.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Evaluaci\u00f3n y consideraciones de replicaci\u00f3n&lt;br&gt;La evaluaci\u00f3n con Language Model Evaluation Harness abarca tareas de SpanishBench, CatalanBench, BasqueBench y GalicianBench. Se observaron variaciones de aproximadamente 1.5% en algunos conjuntos seg\u00fan la versi\u00f3n de Transformers y el uso de paralelismo tensorial, as\u00ed como diferencias debidas a correcciones en tareas/prompting. Los resultados deben interpretarse con cautela, dado que los benchmarks no capturan toda la amplitud de capacidades del modelo.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Evaluaci\u00f3n con LLM-as-a-judge&lt;br&gt;Adem\u00e1s de benchmarks de referencia, se emple\u00f3 Prometheus-2 8\u00d77B como juez para evaluar respuestas del modelo con criterios espec\u00edficos dise\u00f1ados internamente (escalas Likert o tareas binarias, seg\u00fan el caso). Para medir robustez, se usaron tres estilos de prompt por instancia y se calcul\u00f3 la varianza entre puntuaciones. El juez no recibi\u00f3 respuestas de referencia, con el objetivo de evaluar coherencia y calidad intr\u00ednseca.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Consideraciones \u00e9ticas y limitaciones detectadas&lt;br&gt;Las pruebas de sesgo social con BBQ y Regard muestran buen desempe\u00f1o en casos desambiguados, pero resultados pobres en escenarios ambiguos, lo que indica sesgos a mitigar en post-entrenamiento. En sesgos cognitivos, se detectaron efectos de primac\u00eda (preferencia por opciones al inicio) en preguntas tipo test de ARC y sesgo hacia la clase mayoritaria en escenarios few-shot con SST-2, aunque con tama\u00f1os de efecto reducidos. Se recomienda realizar pruebas de seguridad y ajustes adicionales seg\u00fan la aplicaci\u00f3n final.","Modelo Salamandra\u20117B-instruct&lt;br&gt;C\u00f3mo usar Salamandra-7B-Instruct en la pr\u00e1ctica&lt;br&gt;Para inferencia, cargue el modelo 'BSC-LT/salamandra-7b-instruct' con Transformers utilizando device_map='auto' y torch_dtype=torch.bfloat16 cuando sea posible. Genere el prompt con tokenizer.apply_chat_template, indicando los turnos y la fecha, y produzca la respuesta con un l\u00edmite de tokens adecuado (p. ej., max_new_tokens=200\u2013512 seg\u00fan la tarea). En escenarios RAG, incluya los fragmentos recuperados como contexto en el prompt.","Modelo Salamandra\u20117B-instruct&lt;br&gt;Salamandra y RAG&lt;br&gt;Las variantes instruidas de Salamandra funcionan bien en pipelines RAG cuando se integran con un recuperador (BM25 o embeddings) y se pasan al modelo fragmentos de contexto relevantes. El dataset RAG_Multilingual, con decenas de miles de pares pregunta-contexto-respuesta en ca/es/en, es \u00fatil para entrenar y evaluar este tipo de flujos."],"shape":[36],"dtype":"object","order":"little"}]]}}},"view":{"type":"object","name":"CDSView","id":"p3638","attributes":{"filter":{"type":"object","name":"AllIndices","id":"p3639"}}},"glyph":{"type":"object","name":"Scatter","id":"p3634","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":15},"line_color":{"type":"value","value":"white"},"line_alpha":{"type":"value","value":0.96},"fill_color":{"type":"field","field":"topic","transform":{"type":"object","name":"CategoricalColorMapper","id":"p3591","attributes":{"palette":["#1f77b4","#ff7f0e"],"factors":{"type":"ndarray","array":["Aina Kit","Modelo Salamandra\u20117B-instruct"],"shape":[2],"dtype":"object","order":"little"}}}},"fill_alpha":{"type":"value","value":0.96},"hatch_color":{"type":"field","field":"topic","transform":{"id":"p3591"}},"hatch_alpha":{"type":"value","value":0.96}}},"nonselection_glyph":{"type":"object","name":"Scatter","id":"p3635","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":15},"line_color":{"type":"value","value":"white"},"line_alpha":{"type":"value","value":0.1},"fill_color":{"type":"field","field":"topic","transform":{"id":"p3591"}},"fill_alpha":{"type":"value","value":0.1},"hatch_color":{"type":"field","field":"topic","transform":{"id":"p3591"}},"hatch_alpha":{"type":"value","value":0.1}}},"muted_glyph":{"type":"object","name":"Scatter","id":"p3636","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":15},"line_color":{"type":"value","value":"white"},"line_alpha":{"type":"value","value":0.2},"fill_color":{"type":"field","field":"topic","transform":{"id":"p3591"}},"fill_alpha":{"type":"value","value":0.2},"hatch_color":{"type":"field","field":"topic","transform":{"id":"p3591"}},"hatch_alpha":{"type":"value","value":0.2}}}}},{"type":"object","name":"GlyphRenderer","id":"p3649","attributes":{"data_source":{"type":"object","name":"ColumnDataSource","id":"p3640","attributes":{"selected":{"type":"object","name":"Selection","id":"p3641","attributes":{"indices":[],"line_indices":[]}},"selection_policy":{"type":"object","name":"UnionRenderers","id":"p3642"},"data":{"type":"map","entries":[["x",{"type":"ndarray","array":{"type":"bytes","data":""},"shape":[0],"dtype":"float32","order":"little"}],["y",{"type":"ndarray","array":{"type":"bytes","data":""},"shape":[0],"dtype":"float32","order":"little"}],["topic",[]],["question",{"type":"ndarray","array":[],"shape":[0],"dtype":"object","order":"little"}]]}}},"view":{"type":"object","name":"CDSView","id":"p3650","attributes":{"filter":{"type":"object","name":"AllIndices","id":"p3651"}}},"glyph":{"type":"object","name":"Scatter","id":"p3646","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":20},"line_color":{"type":"value","value":"#aaaaaa"},"fill_color":{"type":"value","value":"#aaaaaa"},"hatch_color":{"type":"value","value":"#aaaaaa"},"marker":{"type":"value","value":"x"}}},"nonselection_glyph":{"type":"object","name":"Scatter","id":"p3647","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":20},"line_color":{"type":"value","value":"#aaaaaa"},"line_alpha":{"type":"value","value":0.1},"fill_color":{"type":"value","value":"#aaaaaa"},"fill_alpha":{"type":"value","value":0.1},"hatch_color":{"type":"value","value":"#aaaaaa"},"hatch_alpha":{"type":"value","value":0.1},"marker":{"type":"value","value":"x"}}},"muted_glyph":{"type":"object","name":"Scatter","id":"p3648","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":20},"line_color":{"type":"value","value":"#aaaaaa"},"line_alpha":{"type":"value","value":0.2},"fill_color":{"type":"value","value":"#aaaaaa"},"fill_alpha":{"type":"value","value":0.2},"hatch_color":{"type":"value","value":"#aaaaaa"},"hatch_alpha":{"type":"value","value":0.2},"marker":{"type":"value","value":"x"}}}}},{"type":"object","name":"GlyphRenderer","id":"p3658","attributes":{"data_source":{"type":"object","name":"ColumnDataSource","id":"p3652","attributes":{"selected":{"type":"object","name":"Selection","id":"p3653","attributes":{"indices":[],"line_indices":[]}},"selection_policy":{"type":"object","name":"UnionRenderers","id":"p3654"},"data":{"type":"map","entries":[["x",{"type":"ndarray","array":{"type":"bytes","data":""},"shape":[0],"dtype":"float32","order":"little"}],["y",{"type":"ndarray","array":{"type":"bytes","data":"f+zHQD/TukAFxgxBwtHEQLUlqED037BA5dWSQFeymEB+naZAPxybQER7lUBs9D3AAEEUwOQ6jkBELbRAYxVSwLDHW8CCpCZBRt2eQBWbhkAXWopAtDpPwGq4p0BYaLFA8WweQSOKIkFL9ylBMfUVQVddIUEAshZBt3AqQV/1M0F1MzBBBbU3QYQ7HkEO8gpB"},"shape":[36],"dtype":"float32","order":"little"}]]}}},"view":{"type":"object","name":"CDSView","id":"p3659","attributes":{"filter":{"type":"object","name":"AllIndices","id":"p3660"}}},"glyph":{"type":"object","name":"Scatter","id":"p3655","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":20},"line_color":{"type":"value","value":"#fa9fb5"},"fill_color":{"type":"value","value":"#fa9fb5"},"hatch_color":{"type":"value","value":"#fa9fb5"},"marker":{"type":"value","value":"x"}}},"nonselection_glyph":{"type":"object","name":"Scatter","id":"p3656","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":20},"line_color":{"type":"value","value":"#fa9fb5"},"line_alpha":{"type":"value","value":0.1},"fill_color":{"type":"value","value":"#fa9fb5"},"fill_alpha":{"type":"value","value":0.1},"hatch_color":{"type":"value","value":"#fa9fb5"},"hatch_alpha":{"type":"value","value":0.1},"marker":{"type":"value","value":"x"}}},"muted_glyph":{"type":"object","name":"Scatter","id":"p3657","attributes":{"x":{"type":"field","field":"x"},"y":{"type":"field","field":"y"},"size":{"type":"value","value":20},"line_color":{"type":"value","value":"#fa9fb5"},"line_alpha":{"type":"value","value":0.2},"fill_color":{"type":"value","value":"#fa9fb5"},"fill_alpha":{"type":"value","value":0.2},"hatch_color":{"type":"value","value":"#fa9fb5"},"hatch_alpha":{"type":"value","value":0.2},"marker":{"type":"value","value":"x"}}}}}],"toolbar":{"type":"object","name":"Toolbar","id":"p3601","attributes":{"tools":[{"type":"object","name":"PanTool","id":"p3614"},{"type":"object","name":"WheelZoomTool","id":"p3615","attributes":{"renderers":"auto"}},{"type":"object","name":"BoxZoomTool","id":"p3616","attributes":{"overlay":{"type":"object","name":"BoxAnnotation","id":"p3617","attributes":{"syncable":false,"line_color":"black","line_alpha":1.0,"line_width":2,"line_dash":[4,4],"fill_color":"lightgrey","fill_alpha":0.5,"level":"overlay","visible":false,"left":{"type":"number","value":"nan"},"right":{"type":"number","value":"nan"},"top":{"type":"number","value":"nan"},"bottom":{"type":"number","value":"nan"},"left_units":"canvas","right_units":"canvas","top_units":"canvas","bottom_units":"canvas","handles":{"type":"object","name":"BoxInteractionHandles","id":"p3623","attributes":{"all":{"type":"object","name":"AreaVisuals","id":"p3622","attributes":{"fill_color":"white","hover_fill_color":"lightgray"}}}}}}}},{"type":"object","name":"SaveTool","id":"p3624"},{"type":"object","name":"ResetTool","id":"p3625"},{"type":"object","name":"HelpTool","id":"p3626"},{"type":"object","name":"HoverTool","id":"p3627","attributes":{"renderers":"auto","tooltips":"\n&lt;!--&lt;div style=\"padding: 5px; border: 1px solid #fff157; background-color: #fffff4; max-width: 650px\"&gt;--&gt;\n&lt;div style=\"padding: 15px; border: 0.5px solid; max-width: 650px\"&gt;\n    \n    &lt;div&gt;\n        &lt;span style=\"font-size: 15px; color: #966;\"&gt;[$index]&lt;/span&gt;\n        &lt;span style=\"font-size: 15px; font-weight: bold;\"&gt;VDB index: $index&lt;/span&gt;\n        &lt;span style=\"font-size: 15px; font-weight: bold;\"&gt;Type: @topic&lt;/span&gt;\n        &lt;hr&gt;\n    &lt;/div&gt;\n\n    \n    &lt;div&gt;&lt;span style=\"font-size: 15px;\"&gt;@question&lt;/span&gt;&lt;/div&gt;\n    &lt;div&gt;&lt;span style=\"font-size: 10px; color: #69f;\"&gt;($x, $y)&lt;/span&gt;&lt;/div&gt;\n&lt;/div&gt;\n"}}],"active_scroll":{"id":"p3615"}}},"toolbar_location":"below","left":[{"type":"object","name":"LinearAxis","id":"p3609","attributes":{"ticker":{"type":"object","name":"BasicTicker","id":"p3610","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p3611"},"major_label_policy":{"type":"object","name":"AllLabels","id":"p3612"}}}],"below":[{"type":"object","name":"LinearAxis","id":"p3604","attributes":{"ticker":{"type":"object","name":"BasicTicker","id":"p3605","attributes":{"mantissas":[1,2,5]}},"formatter":{"type":"object","name":"BasicTickFormatter","id":"p3606"},"major_label_policy":{"type":"object","name":"AllLabels","id":"p3607"}}}],"center":[{"type":"object","name":"Grid","id":"p3608","attributes":{"axis":{"id":"p3604"}}},{"type":"object","name":"Grid","id":"p3613","attributes":{"dimension":1,"axis":{"id":"p3609"}}}]}}]}}
    </script>
    <script type="text/javascript">
      (function() {
        const fn = function() {
          Bokeh.safely(function() {
            (function(root) {
              function embed_document(root) {
              const docs_json = document.getElementById('d6204fc8-5f6e-403e-8246-0b496ddc0b68').textContent;
              const render_items = [{"docid":"2344d1c4-eef1-404c-ae45-9b0010feaf3e","roots":{"p3592":"eea16c0c-f0cf-4b3d-95ee-12732e5d07be"},"root_ids":["p3592"]}];
              root.Bokeh.embed.embed_items(docs_json, render_items);
              }
              if (root.Bokeh !== undefined) {
                embed_document(root);
              } else {
                let attempts = 0;
                const timer = setInterval(function(root) {
                  if (root.Bokeh !== undefined) {
                    clearInterval(timer);
                    embed_document(root);
                  } else {
                    attempts++;
                    if (attempts > 100) {
                      clearInterval(timer);
                      console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                    }
                  }
                }, 10, root)
              }
            })(window);
          });
        };
        if (document.readyState != "loading") fn();
        else document.addEventListener("DOMContentLoaded", fn);
      })();
    </script>
  </body>
</html>